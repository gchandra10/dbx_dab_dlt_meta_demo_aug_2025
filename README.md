# dbx_dab_dlt_meta_demo_aug_2025

The 'dbx_dab_dlt_meta_demo_aug_2025' project was generated by using the default-python template.


## Getting started

1. Install the Databricks CLI from https://docs.databricks.com/dev-tools/cli/databricks-cli.html
   
2. Create DAB template

```
$ databricks bundle init
```
- select default-python
- select 'yes' for Notebook sample and DLT sample
- select 'no' for Python Package
- enter a project name in lower case separated by Hyphens
  
DABS will create a folder with project name

3. Authenticate to your Databricks workspace, if you have not done so already:
   
    ```
    $ databricks configure --profile DEFAULT
   ```

    If Developer Token is not allowed, just enter some dummy token and save the profile.
    Open the ```.databrickscfg``` from Home Folder ```C:\Users\userid\.databrickscfg``` or ```/Users/userid/.databrickscfg```
   
   and remove the token and add ```auth_type = databricks-cli```

   Your ```.databrickcfg``` will look like this

   ```
   [DEFAULT]
   host = https://something.cloud.com or databricks.net (no training slash)
   auth_type = databricks-cli   
   ```

4. To Validate & deploy a development copy of this project, type:
   
   ```
   $ databricks bundle validate
   ```

    ```
    $ databricks bundle deploy --target dev
    ```
    (Note that "dev" is the default target, so the `--target` parameter
    is optional here.)

    This deploys everything that's defined for this project.
    For example, the default template would deploy a job called
    `[dev yourname] dbx_dab_dlt_meta_demo_aug_2025_job` to your workspace.
    You can find that job by opening your workpace and clicking on **Workflows**.

5. Similarly, to deploy a production copy, type:
   ```
   $ databricks bundle deploy --target prod
   ```
   Note that the default job from the template has a schedule that runs every day
   (defined in resources/dbx_dab_dlt_meta_demo_aug_2025.job.yml). The schedule
   is paused when deploying in development mode (see
   https://docs.databricks.com/dev-tools/bundles/deployment-modes.html).

6. To run a job or pipeline, use the "run" command:

   ```
   $ databricks bundle run dlt_meta_job -t dev
   ```

7. To delete the Job

   ```
   $ databricks bundle destroy -t dev
   ```

**Important Notes**

- Create a Volume for configuration and copy the .JSON files under conf

```onboard_metadata.py``` has been tweaked to accept values as Task Parameters.

```variables.yml``` containes common values. Feel free to modify as needed.

```people_onboarding_file_path``` points to workspace location instead of Volume.



Optionally, install developer tools such as the Databricks extension for Visual Studio Code from
https://docs.databricks.com/dev-tools/vscode-ext.html.

For documentation on the Databricks asset bundles format used for this project, and for CI/CD configuration, see https://docs.databricks.com/dev-tools/bundles/index.html.
